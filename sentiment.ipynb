{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 00:22:44.932759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-22 00:22:44.932792: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow  as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "model_uri = \"models:/SentimentAnalyzerModel/production\"\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "model.predict([[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon-reviews.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['class'] = le.fit_transform(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.text, data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=150\n",
    "embedding_dim=16\n",
    "num_words=25000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "padded = pad_sequences(sequences, maxlen=maxlen, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=maxlen, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 23:35:54.197690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 23:35:54.198859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.199130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.199323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.199503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.199689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.199863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.200054: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.200227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-05-17 23:35:54.200237: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-17 23:35:54.200493: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 16)           400000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                544       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 400,577\n",
      "Trainable params: 400,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_words,embedding_dim,input_length=maxlen),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "235/235 [==============================] - 3s 7ms/step - loss: 0.6724 - accuracy: 0.6465 - val_loss: 0.6079 - val_accuracy: 0.7480\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4543 - accuracy: 0.8508 - val_loss: 0.3825 - val_accuracy: 0.8632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded, y_train, epochs=2, validation_data=(test_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507999777793884"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).iloc[-1,:][\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 150)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/27 17:52:21 INFO mlflow.utils.conda: Conda environment mlflow-1355c61d10b5da360c91c8bcdf1fb26c9b4aaf7b already exists.\n",
      "2022/06/27 17:52:21 INFO mlflow.projects.utils: === Created directory /tmp/tmpefyfegrh for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/06/27 17:52:21 INFO mlflow.projects.backend.local: === Running command 'source /home/siewe/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1355c61d10b5da360c91c8bcdf1fb26c9b4aaf7b 1>&2 && python sentiment.py 16 10 100 http://localhost:5000' in run with ID '794c2e2e97eb4849bfd77791f57cfe1b' === \n",
      "2022-06-27 17:52:38.509298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:52:38.509320: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-27 17:53:10.749207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-27 17:53:10.750436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.750710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.751157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.751472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.761850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.763668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.768632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.769627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 17:53:10.769646: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-27 17:53:10.790094: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           400000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                544       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 400,577\n",
      "Trainable params: 400,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "235/235 [==============================] - 5s 7ms/step - loss: 0.6623 - accuracy: 0.6524 - val_loss: 0.5765 - val_accuracy: 0.8096\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8572 - val_loss: 0.3632 - val_accuracy: 0.8596\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2494 - accuracy: 0.9153 - val_loss: 0.3174 - val_accuracy: 0.8744\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1689 - accuracy: 0.9440 - val_loss: 0.3137 - val_accuracy: 0.8700\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9637 - val_loss: 0.3202 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9780 - val_loss: 0.3399 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9857 - val_loss: 0.3646 - val_accuracy: 0.8664\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9915 - val_loss: 0.3870 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9944 - val_loss: 0.4298 - val_accuracy: 0.8540\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9979 - val_loss: 0.4318 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/27 17:54:32 INFO mlflow.projects: === Run (ID '794c2e2e97eb4849bfd77791f57cfe1b') succeeded ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.projects.submitted_run.LocalSubmittedRun at 0x7fd3d9d6e2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.run(\".\", parameters={\"embedding_dim\": 16, \"epochs\": 10, \"maxlen\": 100, \"tracking_uri\": tracking_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 18:02:08.212607: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: ~/hadoop/lib/native\n",
      "2022-06-27 18:02:08.212628: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_predict_params(run_id,dest):\n",
    "    model_uri = \"models:/SentimentAnalyzerModel/production\"\n",
    "    tracking_uri = \"http://localhost:5000\"\n",
    "\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    run = mlflow.get_run(run_id)\n",
    "    mlflow.tracking.MlflowClient().download_artifacts(run.info.run_id,\"tokenizer.tok\",dest)\n",
    "    tokenizer = joblib.load(f\"{dest}/tokenizer.tok\")\n",
    "    return tokenizer,run.data.params[\"maxlen\"]\n",
    "\n",
    "\n",
    "def process(sentences,tokenizer, maxlen):\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    padded = pad_sequences(sequences, maxlen=int(maxlen), truncating=\"post\", padding=\"post\")\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, run_id):\n",
    "    import boto3\n",
    "    import json\n",
    "\n",
    "    endpoint_name = \"sentiment-analyzer-api\"\n",
    "    \n",
    "    # get important run params like tokenizer and maxlen\n",
    "    dest = f\"{os.getcwd()}/\"\n",
    "    tokenizer, maxlen = get_predict_params(run_id, dest)\n",
    "    \n",
    "    data = pd.DataFrame(data=process(data, tokenizer, maxlen))\n",
    "\n",
    "    runtime= boto3.client('runtime.sagemaker')\n",
    "\n",
    "    # predict on the first row of the dataset\n",
    "    payload = data.to_json(orient=\"split\")\n",
    "\n",
    "    runtime_response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=payload)\n",
    "    result = json.loads(runtime_response['Body'].read().decode())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': 0.7138702273368835},\n",
       " {'0': 0.18724586069583893},\n",
       " {'0': 0.774770200252533}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "run_id=\"794c2e2e97eb4849bfd77791f57cfe1b\"\n",
    "predict([\n",
    "    \"good to hear that\",\n",
    "    \"very disgusting !\",\n",
    "    \"such an amazing day\"\n",
    "], run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"models:/SentimentAnalyzerModel/production\"\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "dest = \"/home/siewe/Documents/France/Efrei/Cours/M1/Semestre 8/UE - Big Data Fundamentals II - 6/Machine Learning II/Machine Learning Project/downloads\"\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "#run = mlflow.get_run('52ad95415bf043c09402d2cfa2e1eaa7')\n",
    "\n",
    "model = mlflow.keras.load_model(model_uri=model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing new Model to Production...\n",
      "Passing current Production Model to Staging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/29 16:26:26 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: SentimentAnalyzerModel, version 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing new Model to Production...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "name = \"SentimentAnalyzerModel\"\n",
    "\n",
    "# passer la version actuellement en staging en Archived\n",
    "current_staging_version = [int(run.version) for run in client.get_latest_versions(name) if run.current_stage=='Staging'][0]\n",
    "\n",
    "print(\"Passing new Model to Production...\")\n",
    "client.transition_model_version_stage(\n",
    "    name = name,\n",
    "    version=current_staging_version,\n",
    "    stage=\"archived\"\n",
    ")\n",
    "\n",
    "# passer la version actuellement en production en staging\n",
    "current_prod_version = [int(run.version) for run in client.get_latest_versions(name) if run.current_stage=='Production'][0]\n",
    "client.transition_model_version_stage(\n",
    "    name = name,\n",
    "    version=current_prod_version,\n",
    "    stage=\"staging\"\n",
    ")\n",
    "\n",
    "print(\"Passing current Production Model to Staging...\")\n",
    "\n",
    "\n",
    "# recuperer le dernier run et le passer en production\n",
    "run_id = client.list_run_infos('0')[0].run_id\n",
    "desc = \"A new version of the model automatically created\"\n",
    "runs_uri = \"runs:/{}/sentiment-analyzer\".format(run_id)\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(runs_uri)\n",
    "client.create_model_version(name, model_src, run_id, description=desc)\n",
    "\n",
    "new_version = [int(run.version) for run in client.get_latest_versions(name) if run.current_stage=='None'][0]\n",
    "\n",
    "print(\"Passing new Model to Production...\")\n",
    "client.transition_model_version_stage(\n",
    "    name = name,\n",
    "    version=new_version,\n",
    "    stage=\"production\"\n",
    ")\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelVersion: creation_timestamp=1653834243187, current_stage='Archived', description='A new version of the model automatically created', last_updated_timestamp=1653834299477, name='SentimentAnalyzerModel', run_id='4b9fdf5ca3564ccfaf6bdefbb356ceed', run_link='', source='s3://mlflow-bucket-1606/0/4b9fdf5ca3564ccfaf6bdefbb356ceed/artifacts/sentiment-analyzer', status='READY', status_message='', tags={}, user_id='', version='15'>,\n",
       " <ModelVersion: creation_timestamp=1653832418842, current_stage='None', description='A new version of the model automatically created', last_updated_timestamp=1653832418842, name='SentimentAnalyzerModel', run_id='4b9fdf5ca3564ccfaf6bdefbb356ceed', run_link='', source='s3://mlflow-bucket-1606/0/4b9fdf5ca3564ccfaf6bdefbb356ceed/artifacts/sentiment-analyzer', status='READY', status_message='', tags={}, user_id='', version='9'>,\n",
       " <ModelVersion: creation_timestamp=1653833756822, current_stage='Production', description='A new version of the model automatically created', last_updated_timestamp=1653834299477, name='SentimentAnalyzerModel', run_id='4b9fdf5ca3564ccfaf6bdefbb356ceed', run_link='', source='s3://mlflow-bucket-1606/0/4b9fdf5ca3564ccfaf6bdefbb356ceed/artifacts/sentiment-analyzer', status='READY', status_message='', tags={}, user_id='', version='12'>,\n",
       " <ModelVersion: creation_timestamp=1653834185157, current_stage='Staging', description='A new version of the model automatically created', last_updated_timestamp=1653834242803, name='SentimentAnalyzerModel', run_id='4b9fdf5ca3564ccfaf6bdefbb356ceed', run_link='', source='s3://mlflow-bucket-1606/0/4b9fdf5ca3564ccfaf6bdefbb356ceed/artifacts/sentiment-analyzer', status='READY', status_message='', tags={}, user_id='', version='14'>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_latest_versions(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': 0.5535424947738647},\n",
       " {'0': 0.46320345997810364},\n",
       " {'0': 0.5110406875610352}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "tokenizer = joblib.load(f\"{dest}/tokenizer.tok\")\n",
    "predict([\"good to hear that\",\"really disgusting! how can you be so stupid?\",\"such an amazing day\"], tokenizer, maxlen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7536a9785c855d22ece5ddeee27e47d9ec73ab5ff866eee0fb5059c8fcbc56e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
